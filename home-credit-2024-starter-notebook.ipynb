{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Example Notebook\n",
    "\n",
    "Welcome to the example notebook for the Home Credit Kaggle competition. The goal of this competition is to determine how likely a customer is going to default on an issued loan. The main difference between the [first](https://www.kaggle.com/c/home-credit-default-risk) and this competition is that now your submission will be scored with a custom metric that will take into account how well the model performs in future. A decline in performance will be penalized. The goal is to create a model that is stable and performs well in the future.\n",
    "\n",
    "In this notebook you will see how to:\n",
    "* Load the data\n",
    "* Join tables with Polars - a DataFrame library implemented in Rust language, designed to be blazingy fast and memory efficient.  \n",
    "* Create simple aggregation features\n",
    "* Train a LightGBM model\n",
    "* Create a submission table\n",
    "\n",
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T21:24:50.024915Z",
     "iopub.status.busy": "2024-02-07T21:24:50.023647Z",
     "iopub.status.idle": "2024-02-07T21:24:54.729412Z",
     "shell.execute_reply": "2024-02-07T21:24:54.728256Z",
     "shell.execute_reply.started": "2024-02-07T21:24:50.024838Z"
    }
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyarrow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"D:\\\\HOME CREDIT RISK MODEL - KAGGLE\\\\home-credit-credit-risk-model-stability\\\\datasets\" #configured to my system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# current_directory = os.getcwd()\n",
    "# print(\"Current Directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_list = os.listdir(current_directory)\n",
    "# print(\"Folders in Current Directory:\", folder_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T21:24:54.733356Z",
     "iopub.status.busy": "2024-02-07T21:24:54.732337Z",
     "iopub.status.idle": "2024-02-07T21:24:54.746195Z",
     "shell.execute_reply": "2024-02-07T21:24:54.744741Z",
     "shell.execute_reply.started": "2024-02-07T21:24:54.733288Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_table_dtypes(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    # implement here all desired dtypes for tables\n",
    "    # the following is just an example\n",
    "    for col in df.columns:\n",
    "        # last letter of column name will help you determine the type\n",
    "        if col[-1] in (\"P\", \"A\"):\n",
    "            df = df.with_columns(pl.col(col).cast(pl.Float64).alias(col))\n",
    "    #P - Transform DPD (Days past due)\n",
    "    # A - Transform amount\n",
    "    # M - Masking categories\n",
    "    # D - Transform date\n",
    "    # T - Unspecified Transform\n",
    "    # L - Unspecified Transform\n",
    "\n",
    "    return df\n",
    "\n",
    "def convert_strings(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for col in df.columns:  \n",
    "        if df[col].dtype.name in ['object', 'string']:\n",
    "            df[col] = df[col].astype(\"string\").astype('category')\n",
    "            current_categories = df[col].cat.categories\n",
    "            new_categories = current_categories.to_list() + [\"Unknown\"]\n",
    "            new_dtype = pd.CategoricalDtype(categories=new_categories, ordered=True)\n",
    "            df[col] = df[col].astype(new_dtype)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T21:24:54.751423Z",
     "iopub.status.busy": "2024-02-07T21:24:54.749698Z",
     "iopub.status.idle": "2024-02-07T21:25:16.159261Z",
     "shell.execute_reply": "2024-02-07T21:25:16.158289Z",
     "shell.execute_reply.started": "2024-02-07T21:24:54.751353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for train_basetable:  0.20951581001281738\n",
      "Time taken for train_static:  6.136703968048096\n",
      "Time taken for train_static_cb:  1.1614329814910889\n",
      "Time taken for train_person_1:  2.055248260498047\n",
      "Time taken for train_credit_bureau_b_2:  0.1562497615814209\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "train_basetable = pl.read_csv(dataPath + \"\\\\csv_files\\\\train\\\\train_base.csv\")\n",
    "print(\"Time taken for train_basetable: \", time.time() - start_time)\n",
    "\n",
    "start_time = time.time()\n",
    "train_static = pl.concat(\n",
    "    [\n",
    "        pl.read_csv(dataPath + \"\\\\csv_files\\\\train\\\\train_static_0_0.csv\").pipe(set_table_dtypes),\n",
    "        pl.read_csv(dataPath + \"\\\\csv_files\\\\train\\\\train_static_0_1.csv\").pipe(set_table_dtypes),\n",
    "    ],\n",
    "    how=\"vertical_relaxed\",\n",
    ")\n",
    "print(\"Time taken for train_static: \", time.time() - start_time)\n",
    "\n",
    "start_time = time.time()\n",
    "train_static_cb = pl.read_csv(dataPath + \"\\\\csv_files\\\\train\\\\train_static_cb_0.csv\").pipe(set_table_dtypes)\n",
    "print(\"Time taken for train_static_cb: \", time.time() - start_time)\n",
    "\n",
    "# start_time = time.time()\n",
    "# train_tax_registry = pl.concat(\n",
    "#     [pl.read_csv(dataPath + \"\\\\csv_files\\\\train\\\\train_tax_registry_a_1.csv\").pipe(set_table_dtypes),\n",
    "#      pl.read_csv(dataPath + \"\\\\csv_files\\\\train\\\\train_tax_registry_b_1.csv\").pipe(set_table_dtypes),\n",
    "#      pl.read_csv(dataPath + \"\\\\csv_files\\\\train\\\\train_tax_registry_c_1.csv\").pipe(set_table_dtypes)\n",
    "#     ],how=\"vertically_relaxed\"\n",
    "# print(\"Time taken for train_tax_registry: \", time.time() - start_time)\n",
    "\n",
    "start_time = time.time()\n",
    "train_person_1 = pl.read_csv(dataPath + \"\\\\csv_files\\\\train\\\\train_person_1.csv\").pipe(set_table_dtypes)\n",
    "print(\"Time taken for train_person_1: \", time.time() - start_time)\n",
    "\n",
    "start_time = time.time()\n",
    "train_credit_bureau_b_2 = pl.read_csv(dataPath + \"\\\\csv_files\\\\train\\\\train_credit_bureau_b_2.csv\").pipe(set_table_dtypes)\n",
    "print(\"Time taken for train_credit_bureau_b_2: \", time.time() - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# \"train_tax_registry\"\n",
    "train_tax_registry = pl.concat(\n",
    "    [\n",
    "        pl.read_csv(dataPath + \"\\\\csv_files\\\\train\\\\train_credit_bureau_a_1_0.csv\").pipe(set_table_dtypes),\n",
    "        pl.read_csv(dataPath + \"\\\\csv_files\\\\train\\\\train_credit_bureau_a_1_1.csv\").pipe(set_table_dtypes),\n",
    "        pl.read_csv(dataPath + \"\\\\csv_files\\\\train\\\\train_credit_bureau_a_1_2.csv\").pipe(set_table_dtypes),\n",
    "    ],\n",
    "    how=\"vertical_relaxed\",\n",
    ")             \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Time taken for train_tax_registry: \", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Train:  (1526659, 5)\n",
      "STATIC Train:  (1526659, 168)\n",
      "train_static_cb Train:  (1500476, 53)\n",
      "train_person_1 Train:  (2973991, 37)\n",
      "train_credit_bureau_b_2 Train:  (1286755, 6)\n"
     ]
    }
   ],
   "source": [
    "print('Base Train: ',train_basetable.shape)\n",
    "print('STATIC Train: ',train_static.shape)\n",
    "print('train_static_cb Train: ',train_static_cb.shape)\n",
    "print('train_person_1 Train: ',train_person_1.shape)\n",
    "print('train_credit_bureau_b_2 Train: ',train_credit_bureau_b_2.shape)\n",
    "# print('Static Train: ',train_static.head())\n",
    "# print('unique date column values',train_static['validfrom_1069D'].unique().sort())\n",
    "# print('train_static_cb: ',train_static_cb.head())\n",
    "# print('train_person_1: ',train_person_1.head())\n",
    "# print('train_credit_bureau_b_2: ',train_credit_bureau_b_2.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T21:25:16.162856Z",
     "iopub.status.busy": "2024-02-07T21:25:16.161619Z",
     "iopub.status.idle": "2024-02-07T21:25:16.23912Z",
     "shell.execute_reply": "2024-02-07T21:25:16.238115Z",
     "shell.execute_reply.started": "2024-02-07T21:25:16.162811Z"
    }
   },
   "outputs": [],
   "source": [
    "test_basetable = pl.read_csv(dataPath + \"\\\\csv_files\\\\test\\\\test_base.csv\")\n",
    "test_static = pl.concat(\n",
    "    [\n",
    "        pl.read_csv(dataPath + \"\\\\csv_files\\\\test\\\\test_static_0_0.csv\").pipe(set_table_dtypes),\n",
    "        pl.read_csv(dataPath + \"\\\\csv_files\\\\test\\\\test_static_0_1.csv\").pipe(set_table_dtypes),\n",
    "        pl.read_csv(dataPath + \"\\\\csv_files\\\\test\\\\test_static_0_2.csv\").pipe(set_table_dtypes),\n",
    "    ],\n",
    "    how=\"vertical_relaxed\",\n",
    ")\n",
    "test_static_cb = pl.read_csv(dataPath + \"\\\\csv_files\\\\test\\\\test_static_cb_0.csv\").pipe(set_table_dtypes)\n",
    "test_person_1 = pl.read_csv(dataPath + \"\\\\csv_files\\\\test\\\\test_person_1.csv\").pipe(set_table_dtypes) \n",
    "test_credit_bureau_b_2 = pl.read_csv(dataPath + \"\\\\csv_files\\\\test\\\\test_credit_bureau_b_2.csv\").pipe(set_table_dtypes) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "In this part, we can see a simple example of joining tables via `case_id`. Here the loading and joining is done with polars library. Polars library is blazingly fast and has much smaller memory footprint than pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T21:25:16.24119Z",
     "iopub.status.busy": "2024-02-07T21:25:16.24057Z",
     "iopub.status.idle": "2024-02-07T21:25:18.454532Z",
     "shell.execute_reply": "2024-02-07T21:25:18.452798Z",
     "shell.execute_reply.started": "2024-02-07T21:25:16.241152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amtinstpaidbefduel24m_4187115A', 'annuity_780A', 'annuitynextmonth_57A', 'avginstallast24m_3658937A', 'avglnamtstart24m_4525187A', 'avgoutstandbalancel6m_4187114A', 'avgpmtlast12m_4525200A', 'credamount_770A', 'currdebt_22A', 'currdebtcredtyperange_828A', 'disbursedcredamount_1113A', 'downpmt_116A', 'inittransactionamount_650A', 'lastapprcommoditycat_1041M', 'lastapprcommoditytypec_5251766M', 'lastapprcredamount_781A', 'lastcancelreason_561M', 'lastotherinc_902A', 'lastotherlnsexpense_631A', 'lastrejectcommoditycat_161M', 'lastrejectcommodtypec_5251769M', 'lastrejectcredamount_222A', 'lastrejectreason_759M', 'lastrejectreasonclient_4145040M', 'maininc_215A', 'maxannuity_159A', 'maxannuity_4075009A', 'maxdebt4_972A', 'maxinstallast24m_3658928A', 'maxlnamtstart6m_4525199A', 'maxoutstandbalancel12m_4187113A', 'maxpmtlast3m_4525190A', 'previouscontdistrict_112M', 'price_1097A', 'sumoutstandtotal_3546847A', 'sumoutstandtotalest_4493215A', 'totaldebt_9A', 'totalsettled_863A', 'totinstallast1m_4525188A']\n",
      "['description_5085714M', 'education_1103M', 'education_88M', 'maritalst_385M', 'maritalst_893M', 'pmtaverage_3A', 'pmtaverage_4527227A', 'pmtaverage_4955615A', 'pmtssum_45A']\n"
     ]
    }
   ],
   "source": [
    "# We need to use aggregation functions in tables with depth > 1, so tables that contain num_group1 column or \n",
    "# also num_group2 column.\n",
    "train_person_1_feats_1 = train_person_1.group_by(\"case_id\").agg(\n",
    "    pl.col(\"mainoccupationinc_384A\").max().alias(\"mainoccupationinc_384A_max\"),\n",
    "    (pl.col(\"incometype_1044T\") == \"SELFEMPLOYED\").max().alias(\"mainoccupationinc_384A_any_selfemployed\")\n",
    ")\n",
    "\n",
    "# Here num_group1=0 has special meaning, it is the person who applied for the loan.\n",
    "train_person_1_feats_2 = train_person_1.select([\"case_id\", \"num_group1\", \"housetype_905L\"]).filter(\n",
    "    pl.col(\"num_group1\") == 0\n",
    ").drop(\"num_group1\").rename({\"housetype_905L\": \"person_housetype\"})\n",
    "\n",
    "# Here we have num_goup1 and num_group2, so we need to aggregate again.\n",
    "train_credit_bureau_b_2_feats = train_credit_bureau_b_2.group_by(\"case_id\").agg(\n",
    "    pl.col(\"pmts_pmtsoverdue_635A\").max().alias(\"pmts_pmtsoverdue_635A_max\"),\n",
    "    (pl.col(\"pmts_dpdvalue_108P\") > 31).max().alias(\"pmts_dpdvalue_108P_over31\")\n",
    ")\n",
    "\n",
    "# We will process in this examples only A-type and M-type columns, so we need to select them.\n",
    "selected_static_cols = []\n",
    "for col in train_static.columns:\n",
    "    if col[-1] in (\"A\", \"M\"):\n",
    "        selected_static_cols.append(col)\n",
    "print(selected_static_cols)\n",
    "\n",
    "selected_static_cb_cols = []\n",
    "for col in train_static_cb.columns:\n",
    "    if col[-1] in (\"A\", \"M\"):\n",
    "        selected_static_cb_cols.append(col)\n",
    "print(selected_static_cb_cols)\n",
    "\n",
    "# Join all tables together.\n",
    "data = train_basetable.join(\n",
    "    train_static.select([\"case_id\"]+selected_static_cols), how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    train_static_cb.select([\"case_id\"]+selected_static_cb_cols), how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    train_person_1_feats_1, how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    train_person_1_feats_2, how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    train_credit_bureau_b_2_feats, how=\"left\", on=\"case_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T21:25:18.456308Z",
     "iopub.status.busy": "2024-02-07T21:25:18.455848Z",
     "iopub.status.idle": "2024-02-07T21:25:18.474933Z",
     "shell.execute_reply": "2024-02-07T21:25:18.473491Z",
     "shell.execute_reply.started": "2024-02-07T21:25:18.456258Z"
    }
   },
   "outputs": [],
   "source": [
    "test_person_1_feats_1 = test_person_1.group_by(\"case_id\").agg(\n",
    "    pl.col(\"mainoccupationinc_384A\").max().alias(\"mainoccupationinc_384A_max\"),\n",
    "    (pl.col(\"incometype_1044T\") == \"SELFEMPLOYED\").max().alias(\"mainoccupationinc_384A_any_selfemployed\")\n",
    ")\n",
    "\n",
    "test_person_1_feats_2 = test_person_1.select([\"case_id\", \"num_group1\", \"housetype_905L\"]).filter(\n",
    "    pl.col(\"num_group1\") == 0\n",
    ").drop(\"num_group1\").rename({\"housetype_905L\": \"person_housetype\"})\n",
    "\n",
    "test_credit_bureau_b_2_feats = test_credit_bureau_b_2.group_by(\"case_id\").agg(\n",
    "    pl.col(\"pmts_pmtsoverdue_635A\").max().alias(\"pmts_pmtsoverdue_635A_max\"),\n",
    "    (pl.col(\"pmts_dpdvalue_108P\") > 31).max().alias(\"pmts_dpdvalue_108P_over31\")\n",
    ")\n",
    "\n",
    "data_submission = test_basetable.join(\n",
    "    test_static.select([\"case_id\"]+selected_static_cols), how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    test_static_cb.select([\"case_id\"]+selected_static_cb_cols), how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    test_person_1_feats_1, how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    test_person_1_feats_2, how=\"left\", on=\"case_id\"\n",
    ").join(\n",
    "    test_credit_bureau_b_2_feats, how=\"left\", on=\"case_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T21:25:18.477539Z",
     "iopub.status.busy": "2024-02-07T21:25:18.47705Z",
     "iopub.status.idle": "2024-02-07T21:25:28.525841Z",
     "shell.execute_reply": "2024-02-07T21:25:28.524407Z",
     "shell.execute_reply.started": "2024-02-07T21:25:18.477494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amtinstpaidbefduel24m_4187115A', 'annuity_780A', 'annuitynextmonth_57A', 'avginstallast24m_3658937A', 'avglnamtstart24m_4525187A', 'avgoutstandbalancel6m_4187114A', 'avgpmtlast12m_4525200A', 'credamount_770A', 'currdebt_22A', 'currdebtcredtyperange_828A', 'disbursedcredamount_1113A', 'downpmt_116A', 'inittransactionamount_650A', 'lastapprcommoditycat_1041M', 'lastapprcommoditytypec_5251766M', 'lastapprcredamount_781A', 'lastcancelreason_561M', 'lastotherinc_902A', 'lastotherlnsexpense_631A', 'lastrejectcommoditycat_161M', 'lastrejectcommodtypec_5251769M', 'lastrejectcredamount_222A', 'lastrejectreason_759M', 'lastrejectreasonclient_4145040M', 'maininc_215A', 'maxannuity_159A', 'maxannuity_4075009A', 'maxdebt4_972A', 'maxinstallast24m_3658928A', 'maxlnamtstart6m_4525199A', 'maxoutstandbalancel12m_4187113A', 'maxpmtlast3m_4525190A', 'previouscontdistrict_112M', 'price_1097A', 'sumoutstandtotal_3546847A', 'sumoutstandtotalest_4493215A', 'totaldebt_9A', 'totalsettled_863A', 'totinstallast1m_4525188A', 'description_5085714M', 'education_1103M', 'education_88M', 'maritalst_385M', 'maritalst_893M', 'pmtaverage_3A', 'pmtaverage_4527227A', 'pmtaverage_4955615A', 'pmtssum_45A']\n"
     ]
    }
   ],
   "source": [
    "case_ids = data[\"case_id\"].unique().shuffle(seed=1)\n",
    "case_ids_train, case_ids_test = train_test_split(case_ids, train_size=0.6, random_state=1)\n",
    "case_ids_valid, case_ids_test = train_test_split(case_ids_test, train_size=0.5, random_state=1)\n",
    "\n",
    "cols_pred = []\n",
    "for col in data.columns:\n",
    "    if col[-1].isupper() and col[:-1].islower():\n",
    "        cols_pred.append(col)\n",
    "\n",
    "print(cols_pred)\n",
    "\n",
    "def from_polars_to_pandas(case_ids: pl.DataFrame) -> pl.DataFrame:\n",
    "    return (\n",
    "        data.filter(pl.col(\"case_id\").is_in(case_ids))[[\"case_id\", \"WEEK_NUM\", \"target\"]].to_pandas(),\n",
    "        data.filter(pl.col(\"case_id\").is_in(case_ids))[cols_pred].to_pandas(),\n",
    "        data.filter(pl.col(\"case_id\").is_in(case_ids))[\"target\"].to_pandas()\n",
    "    )\n",
    "\n",
    "base_train, X_train, y_train = from_polars_to_pandas(case_ids_train)\n",
    "base_valid, X_valid, y_valid = from_polars_to_pandas(case_ids_valid)\n",
    "base_test, X_test, y_test = from_polars_to_pandas(case_ids_test)\n",
    "\n",
    "for df in [X_train, X_valid, X_test]:\n",
    "    df = convert_strings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T21:25:28.529014Z",
     "iopub.status.busy": "2024-02-07T21:25:28.52813Z",
     "iopub.status.idle": "2024-02-07T21:25:28.534479Z",
     "shell.execute_reply": "2024-02-07T21:25:28.53334Z",
     "shell.execute_reply.started": "2024-02-07T21:25:28.528913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (915995, 48)\n",
      "Valid: (305332, 48)\n",
      "Test: (305332, 48)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {X_train.shape}\")\n",
    "print(f\"Valid: {X_valid.shape}\")\n",
    "print(f\"Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training LightGBM\n",
    "\n",
    "Minimal example of LightGBM training is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T21:25:28.536641Z",
     "iopub.status.busy": "2024-02-07T21:25:28.535756Z",
     "iopub.status.idle": "2024-02-07T21:26:56.543315Z",
     "shell.execute_reply": "2024-02-07T21:26:56.541627Z",
     "shell.execute_reply.started": "2024-02-07T21:25:28.5366Z"
    }
   },
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "lgb_valid = lgb.Dataset(X_valid, label=y_valid, reference=lgb_train)\n",
    "\n",
    "params = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"max_depth\": 3,\n",
    "    \"num_leaves\": 31,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_fraction\": 0.9,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"n_estimators\": 1000,\n",
    "    \"verbose\": -1,\n",
    "}\n",
    "\n",
    "gbm = lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    valid_sets=lgb_valid,\n",
    "    callbacks=[lgb.log_evaluation(50), lgb.early_stopping(10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation with AUC and then comparison with the stability metric is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T21:26:56.547522Z",
     "iopub.status.busy": "2024-02-07T21:26:56.547044Z",
     "iopub.status.idle": "2024-02-07T21:27:22.5052Z",
     "shell.execute_reply": "2024-02-07T21:27:22.503776Z",
     "shell.execute_reply.started": "2024-02-07T21:26:56.547479Z"
    }
   },
   "outputs": [],
   "source": [
    "for base, X in [(base_train, X_train), (base_valid, X_valid), (base_test, X_test)]:\n",
    "    y_pred = gbm.predict(X, num_iteration=gbm.best_iteration)\n",
    "    base[\"score\"] = y_pred\n",
    "\n",
    "print(f'The AUC score on the train set is: {roc_auc_score(base_train[\"target\"], base_train[\"score\"])}') \n",
    "print(f'The AUC score on the valid set is: {roc_auc_score(base_valid[\"target\"], base_valid[\"score\"])}') \n",
    "print(f'The AUC score on the test set is: {roc_auc_score(base_test[\"target\"], base_test[\"score\"])}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T21:27:22.507036Z",
     "iopub.status.busy": "2024-02-07T21:27:22.506645Z",
     "iopub.status.idle": "2024-02-07T21:27:23.796452Z",
     "shell.execute_reply": "2024-02-07T21:27:23.79501Z",
     "shell.execute_reply.started": "2024-02-07T21:27:22.507Z"
    }
   },
   "outputs": [],
   "source": [
    "def gini_stability(base, w_fallingrate=88.0, w_resstd=-0.5):\n",
    "    gini_in_time = base.loc[:, [\"WEEK_NUM\", \"target\", \"score\"]]\\\n",
    "        .sort_values(\"WEEK_NUM\")\\\n",
    "        .groupby(\"WEEK_NUM\")[[\"target\", \"score\"]]\\\n",
    "        .apply(lambda x: 2*roc_auc_score(x[\"target\"], x[\"score\"])-1).tolist()\n",
    "    \n",
    "    x = np.arange(len(gini_in_time))\n",
    "    y = gini_in_time\n",
    "    a, b = np.polyfit(x, y, 1)\n",
    "    y_hat = a*x + b\n",
    "    residuals = y - y_hat\n",
    "    res_std = np.std(residuals)\n",
    "    avg_gini = np.mean(gini_in_time)\n",
    "    return avg_gini + w_fallingrate * min(0, a) + w_resstd * res_std\n",
    "\n",
    "stability_score_train = gini_stability(base_train)\n",
    "stability_score_valid = gini_stability(base_valid)\n",
    "stability_score_test = gini_stability(base_test)\n",
    "\n",
    "print(f'The stability score on the train set is: {stability_score_train}') \n",
    "print(f'The stability score on the valid set is: {stability_score_valid}') \n",
    "print(f'The stability score on the test set is: {stability_score_test}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Scoring the submission dataset is below, we need to take care of new categories. Then we save the score as a last step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T21:27:23.798639Z",
     "iopub.status.busy": "2024-02-07T21:27:23.798139Z",
     "iopub.status.idle": "2024-02-07T21:27:23.946242Z",
     "shell.execute_reply": "2024-02-07T21:27:23.944996Z",
     "shell.execute_reply.started": "2024-02-07T21:27:23.798595Z"
    }
   },
   "outputs": [],
   "source": [
    "X_submission = data_submission[cols_pred].to_pandas()\n",
    "X_submission = convert_strings(X_submission)\n",
    "categorical_cols = X_train.select_dtypes(include=['category']).columns\n",
    "\n",
    "for col in categorical_cols:\n",
    "    train_categories = set(X_train[col].cat.categories)\n",
    "    submission_categories = set(X_submission[col].cat.categories)\n",
    "    new_categories = submission_categories - train_categories\n",
    "    X_submission.loc[X_submission[col].isin(new_categories), col] = \"Unknown\"\n",
    "    new_dtype = pd.CategoricalDtype(categories=train_categories, ordered=True)\n",
    "    X_train[col] = X_train[col].astype(new_dtype)\n",
    "    X_submission[col] = X_submission[col].astype(new_dtype)\n",
    "\n",
    "y_submission_pred = gbm.predict(X_submission, num_iteration=gbm.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T21:27:23.948164Z",
     "iopub.status.busy": "2024-02-07T21:27:23.947771Z",
     "iopub.status.idle": "2024-02-07T21:27:23.96104Z",
     "shell.execute_reply": "2024-02-07T21:27:23.959969Z",
     "shell.execute_reply.started": "2024-02-07T21:27:23.948128Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"case_id\": data_submission[\"case_id\"].to_numpy(),\n",
    "    \"score\": y_submission_pred\n",
    "}).set_index('case_id')\n",
    "submission.to_csv(\"./submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best of luck, and most importantly, enjoy the process of learning and discovery! \n",
    "\n",
    "<img src=\"https://i.imgur.com/obVWIBh.png\" alt=\"Image\" width=\"700\"/>"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7602123,
     "sourceId": 50160,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
